---
layout: post
title:  "Transformer"
subtitle: "Transformer(1)"
categories: projects
tags: blog github pages jekyll spacy transformer
comments: true
---

## 개요
>  논문 'Attention is All You Need'에서 설명하는 Transformer을 구현해 볼 것이다.
> 전체적인 내용은 [다음 글](https://github.com/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb)을 참고 했습니다.

- 목차
  - Preparing Data
  - Encoder

https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb
